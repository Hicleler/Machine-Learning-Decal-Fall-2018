{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Word2Vec in Gensim and making it work!\n",
    "\n",
    "The idea behind Word2Vec is pretty simple. We are making and assumption that you can tell the meaning of a word by the company it keeps. This is analogous to the saying *show me your friends, and I'll tell who you are*. So if you have two words that have very similar neighbors (i.e. the usage context is about the same), then these words are probably quite similar in meaning or are at least highly related. For example, the words `shocked`,`appalled` and `astonished` are typically used in a similar context. \n",
    "\n",
    "In this tutorial, you will learn how to use the Gensim implementation of Word2Vec and actually get it to work! I have heard a lot of complaints about poor performance etc, but its really a combination of two things, (1) your input data and (2) your parameter settings. Note that the training algorithms in this package were ported from the [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) and extended with additional functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and logging\n",
    "\n",
    "First, we start with our imports and get logging established:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed and set up logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Next, is our dataset. The secret to getting Word2Vec really working for you is to have lots and lots of text data. In this case I am going to use data from the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset. This dataset has full user reviews of cars and hotels. I have specifically concatenated all of the hotel reviews into one big file which is about 97MB compressed and 229MB uncompressed. We will use the compressed file for this tutorial. Each line in this file represents a hotel review. You can download the OpinRank Word2Vec dataset here.\n",
    "\n",
    "To avoid confusion, while gensim’s word2vec tutorial says that you need to pass it a sequence of sentences as its input, you can always pass it a whole review as a sentence (i.e. a much larger size of text), and it should not make much of a difference. \n",
    "\n",
    "Now, let's take a closer look at this data below by printing the first line. You can see that this is a pretty hefty review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file=\"reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open ('reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files into a list\n",
    "Now that we've had a sneak peak of our dataset, we can read it into a list so that we can pass this on to the Word2Vec model. Notice in the code below, that I am directly reading the \n",
    "compressed file. I'm also doing a mild pre-processing of the reviews using `gensim.utils.simple_preprocess (line)`. This does some basic pre-processing such as tokenization, lowercasing, etc and returns back a list of tokens (words). Documentation of this pre-processing method can be found on the official [Gensim documentation site](https://radimrehurek.com/gensim/utils.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:20:45,670 : INFO : reading file reviews_data.txt.gz...this may take a while\n",
      "2018-10-23 14:20:45,672 : INFO : read 0 reviews\n",
      "2018-10-23 14:20:47,824 : INFO : read 10000 reviews\n",
      "2018-10-23 14:20:49,912 : INFO : read 20000 reviews\n",
      "2018-10-23 14:20:52,373 : INFO : read 30000 reviews\n",
      "2018-10-23 14:20:54,715 : INFO : read 40000 reviews\n",
      "2018-10-23 14:20:57,520 : INFO : read 50000 reviews\n",
      "2018-10-23 14:21:00,099 : INFO : read 60000 reviews\n",
      "2018-10-23 14:21:03,006 : INFO : read 70000 reviews\n",
      "2018-10-23 14:21:05,371 : INFO : read 80000 reviews\n",
      "2018-10-23 14:21:07,852 : INFO : read 90000 reviews\n",
      "2018-10-23 14:21:10,561 : INFO : read 100000 reviews\n",
      "2018-10-23 14:21:12,706 : INFO : read 110000 reviews\n",
      "2018-10-23 14:21:14,900 : INFO : read 120000 reviews\n",
      "2018-10-23 14:21:17,227 : INFO : read 130000 reviews\n",
      "2018-10-23 14:21:19,796 : INFO : read 140000 reviews\n",
      "2018-10-23 14:21:22,375 : INFO : read 150000 reviews\n",
      "2018-10-23 14:21:25,925 : INFO : read 160000 reviews\n",
      "2018-10-23 14:21:28,386 : INFO : read 170000 reviews\n",
      "2018-10-23 14:21:30,615 : INFO : read 180000 reviews\n",
      "2018-10-23 14:21:32,848 : INFO : read 190000 reviews\n",
      "2018-10-23 14:21:35,164 : INFO : read 200000 reviews\n",
      "2018-10-23 14:21:37,930 : INFO : read 210000 reviews\n",
      "2018-10-23 14:21:40,433 : INFO : read 220000 reviews\n",
      "2018-10-23 14:21:42,504 : INFO : read 230000 reviews\n",
      "2018-10-23 14:21:49,510 : INFO : read 240000 reviews\n",
      "2018-10-23 14:21:53,114 : INFO : read 250000 reviews\n",
      "2018-10-23 14:21:54,201 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "            yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "# read the tokenized reviews into a list\n",
    "# each review item becomes a serries of words\n",
    "# so this becomes a list of lists\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Done reading data file\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec model\n",
    "\n",
    "Training the model is fairly straightforward. You just instantiate Word2Vec and pass the reviews that we read in the previous step (the `documents`). So, we are essentially passing on a list of lists. Where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary. And by vocabulary, I mean a set of unique words.\n",
    "\n",
    "After building the vocabulary, we just need to call `train(...)` to start training the Word2Vec model. Training on the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset takes about 10 minutes so please be patient while running your code on this dataset.\n",
    "\n",
    "Behind the scenes we are actually training a simple neural network with a single hidden layer. But, we are actually not going to use the neural network after training. Instead, the goal is to learn the weights of the hidden layer. These weights are essentially the word vectors that we’re trying to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:07:17,782 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-10-23 14:07:17,783 : INFO : collecting all words and their counts\n",
      "2018-10-23 14:07:17,784 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-10-23 14:07:18,033 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2018-10-23 14:07:18,275 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2018-10-23 14:07:18,553 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2018-10-23 14:07:18,815 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2018-10-23 14:07:19,120 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2018-10-23 14:07:19,447 : INFO : PROGRESS: at sentence #60000, processed 11013723 words, keeping 76781 word types\n",
      "2018-10-23 14:07:19,705 : INFO : PROGRESS: at sentence #70000, processed 12637525 words, keeping 83194 word types\n",
      "2018-10-23 14:07:19,950 : INFO : PROGRESS: at sentence #80000, processed 14099751 words, keeping 88454 word types\n",
      "2018-10-23 14:07:20,170 : INFO : PROGRESS: at sentence #90000, processed 15662149 words, keeping 93352 word types\n",
      "2018-10-23 14:07:20,379 : INFO : PROGRESS: at sentence #100000, processed 17164487 words, keeping 97881 word types\n",
      "2018-10-23 14:07:20,593 : INFO : PROGRESS: at sentence #110000, processed 18652292 words, keeping 102127 word types\n",
      "2018-10-23 14:07:20,862 : INFO : PROGRESS: at sentence #120000, processed 20152529 words, keeping 105918 word types\n",
      "2018-10-23 14:07:21,163 : INFO : PROGRESS: at sentence #130000, processed 21684330 words, keeping 110099 word types\n",
      "2018-10-23 14:07:21,489 : INFO : PROGRESS: at sentence #140000, processed 23330206 words, keeping 114103 word types\n",
      "2018-10-23 14:07:21,822 : INFO : PROGRESS: at sentence #150000, processed 24838754 words, keeping 118169 word types\n",
      "2018-10-23 14:07:22,126 : INFO : PROGRESS: at sentence #160000, processed 26390910 words, keeping 118665 word types\n",
      "2018-10-23 14:07:22,343 : INFO : PROGRESS: at sentence #170000, processed 27913916 words, keeping 123350 word types\n",
      "2018-10-23 14:07:22,609 : INFO : PROGRESS: at sentence #180000, processed 29535612 words, keeping 126742 word types\n",
      "2018-10-23 14:07:22,881 : INFO : PROGRESS: at sentence #190000, processed 31096459 words, keeping 129841 word types\n",
      "2018-10-23 14:07:23,127 : INFO : PROGRESS: at sentence #200000, processed 32805271 words, keeping 133249 word types\n",
      "2018-10-23 14:07:23,372 : INFO : PROGRESS: at sentence #210000, processed 34434198 words, keeping 136358 word types\n",
      "2018-10-23 14:07:23,663 : INFO : PROGRESS: at sentence #220000, processed 36083482 words, keeping 139412 word types\n",
      "2018-10-23 14:07:23,910 : INFO : PROGRESS: at sentence #230000, processed 37571762 words, keeping 142393 word types\n",
      "2018-10-23 14:07:24,234 : INFO : PROGRESS: at sentence #240000, processed 39138190 words, keeping 145226 word types\n",
      "2018-10-23 14:07:24,463 : INFO : PROGRESS: at sentence #250000, processed 40695049 words, keeping 147960 word types\n",
      "2018-10-23 14:07:24,617 : INFO : collected 150053 word types from a corpus of 41519355 raw words and 255404 sentences\n",
      "2018-10-23 14:07:24,618 : INFO : Loading a fresh vocabulary\n",
      "2018-10-23 14:07:25,584 : INFO : effective_min_count=2 retains 70538 unique words (47% of original 150053, drops 79515)\n",
      "2018-10-23 14:07:25,585 : INFO : effective_min_count=2 leaves 41439840 word corpus (99% of original 41519355, drops 79515)\n",
      "2018-10-23 14:07:25,783 : INFO : deleting the raw counts dictionary of 150053 items\n",
      "2018-10-23 14:07:25,787 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2018-10-23 14:07:25,788 : INFO : downsampling leaves estimated 30349255 word corpus (73.2% of prior 41439840)\n",
      "2018-10-23 14:07:26,020 : INFO : estimated required memory for 70538 words and 150 dimensions: 119914600 bytes\n",
      "2018-10-23 14:07:26,021 : INFO : resetting layer weights\n",
      "2018-10-23 14:07:26,836 : INFO : training model with 10 workers on 70538 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-10-23 14:07:27,848 : INFO : EPOCH 1 - PROGRESS: at 3.57% examples, 1102355 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:07:28,849 : INFO : EPOCH 1 - PROGRESS: at 6.31% examples, 969262 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:29,849 : INFO : EPOCH 1 - PROGRESS: at 9.52% examples, 991294 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:07:30,870 : INFO : EPOCH 1 - PROGRESS: at 11.78% examples, 957860 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:07:31,876 : INFO : EPOCH 1 - PROGRESS: at 14.41% examples, 946499 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:07:32,887 : INFO : EPOCH 1 - PROGRESS: at 16.85% examples, 928962 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:07:33,896 : INFO : EPOCH 1 - PROGRESS: at 19.14% examples, 917152 words/s, in_qsize 19, out_qsize 2\n",
      "2018-10-23 14:07:34,897 : INFO : EPOCH 1 - PROGRESS: at 22.18% examples, 935690 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:35,902 : INFO : EPOCH 1 - PROGRESS: at 24.98% examples, 946387 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:36,928 : INFO : EPOCH 1 - PROGRESS: at 28.34% examples, 940269 words/s, in_qsize 20, out_qsize 6\n",
      "2018-10-23 14:07:37,938 : INFO : EPOCH 1 - PROGRESS: at 31.56% examples, 934622 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:38,954 : INFO : EPOCH 1 - PROGRESS: at 35.14% examples, 943313 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:39,971 : INFO : EPOCH 1 - PROGRESS: at 38.78% examples, 947533 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:40,973 : INFO : EPOCH 1 - PROGRESS: at 41.91% examples, 940580 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:41,986 : INFO : EPOCH 1 - PROGRESS: at 45.07% examples, 935717 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:07:43,000 : INFO : EPOCH 1 - PROGRESS: at 48.31% examples, 935430 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:44,005 : INFO : EPOCH 1 - PROGRESS: at 51.89% examples, 940941 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:45,007 : INFO : EPOCH 1 - PROGRESS: at 55.42% examples, 946662 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:46,010 : INFO : EPOCH 1 - PROGRESS: at 58.89% examples, 949436 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:47,015 : INFO : EPOCH 1 - PROGRESS: at 62.17% examples, 949955 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:07:48,041 : INFO : EPOCH 1 - PROGRESS: at 65.81% examples, 951854 words/s, in_qsize 20, out_qsize 2\n",
      "2018-10-23 14:07:49,066 : INFO : EPOCH 1 - PROGRESS: at 69.19% examples, 953195 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:50,070 : INFO : EPOCH 1 - PROGRESS: at 71.95% examples, 949269 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:51,076 : INFO : EPOCH 1 - PROGRESS: at 74.98% examples, 945463 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:07:52,094 : INFO : EPOCH 1 - PROGRESS: at 78.10% examples, 947290 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:53,120 : INFO : EPOCH 1 - PROGRESS: at 81.32% examples, 947890 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:54,141 : INFO : EPOCH 1 - PROGRESS: at 84.27% examples, 944878 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:07:55,151 : INFO : EPOCH 1 - PROGRESS: at 87.33% examples, 943182 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:56,167 : INFO : EPOCH 1 - PROGRESS: at 90.42% examples, 940081 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:57,177 : INFO : EPOCH 1 - PROGRESS: at 94.07% examples, 943975 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:07:58,185 : INFO : EPOCH 1 - PROGRESS: at 97.49% examples, 945125 words/s, in_qsize 15, out_qsize 4\n",
      "2018-10-23 14:07:58,811 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:07:58,812 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:07:58,816 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:07:58,838 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:07:58,839 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:07:58,843 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:07:58,844 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:07:58,852 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:07:58,856 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:07:58,859 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:07:58,859 : INFO : EPOCH - 1 : training on 41519355 raw words (30349310 effective words) took 32.0s, 947858 effective words/s\n",
      "2018-10-23 14:07:59,880 : INFO : EPOCH 2 - PROGRESS: at 3.15% examples, 960545 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:08:00,881 : INFO : EPOCH 2 - PROGRESS: at 6.47% examples, 987389 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:08:01,892 : INFO : EPOCH 2 - PROGRESS: at 9.53% examples, 988027 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:08:02,902 : INFO : EPOCH 2 - PROGRESS: at 12.26% examples, 1000547 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:03,910 : INFO : EPOCH 2 - PROGRESS: at 15.21% examples, 997886 words/s, in_qsize 14, out_qsize 6\n",
      "2018-10-23 14:08:04,921 : INFO : EPOCH 2 - PROGRESS: at 18.13% examples, 1006216 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:05,923 : INFO : EPOCH 2 - PROGRESS: at 20.64% examples, 1002614 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:06,923 : INFO : EPOCH 2 - PROGRESS: at 23.52% examples, 1000988 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:08:07,942 : INFO : EPOCH 2 - PROGRESS: at 26.93% examples, 1003732 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:08,959 : INFO : EPOCH 2 - PROGRESS: at 30.57% examples, 1002556 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:09,964 : INFO : EPOCH 2 - PROGRESS: at 34.19% examples, 1004130 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:10,990 : INFO : EPOCH 2 - PROGRESS: at 37.86% examples, 1006022 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:08:11,992 : INFO : EPOCH 2 - PROGRESS: at 41.59% examples, 1006658 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:12,992 : INFO : EPOCH 2 - PROGRESS: at 45.19% examples, 1005749 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:14,006 : INFO : EPOCH 2 - PROGRESS: at 48.57% examples, 1003104 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:08:15,014 : INFO : EPOCH 2 - PROGRESS: at 52.10% examples, 1003683 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:16,016 : INFO : EPOCH 2 - PROGRESS: at 55.50% examples, 1003942 words/s, in_qsize 19, out_qsize 1\n",
      "2018-10-23 14:08:17,027 : INFO : EPOCH 2 - PROGRESS: at 59.10% examples, 1005289 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:18,036 : INFO : EPOCH 2 - PROGRESS: at 62.54% examples, 1004938 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:19,045 : INFO : EPOCH 2 - PROGRESS: at 66.31% examples, 1007416 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:08:20,057 : INFO : EPOCH 2 - PROGRESS: at 69.73% examples, 1007780 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:08:21,061 : INFO : EPOCH 2 - PROGRESS: at 73.42% examples, 1011266 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:22,063 : INFO : EPOCH 2 - PROGRESS: at 76.82% examples, 1013191 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:23,070 : INFO : EPOCH 2 - PROGRESS: at 80.13% examples, 1013919 words/s, in_qsize 19, out_qsize 2\n",
      "2018-10-23 14:08:24,073 : INFO : EPOCH 2 - PROGRESS: at 83.76% examples, 1016947 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:25,088 : INFO : EPOCH 2 - PROGRESS: at 87.29% examples, 1017878 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:26,102 : INFO : EPOCH 2 - PROGRESS: at 91.01% examples, 1018193 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:27,119 : INFO : EPOCH 2 - PROGRESS: at 93.49% examples, 1007551 words/s, in_qsize 14, out_qsize 5\n",
      "2018-10-23 14:08:28,143 : INFO : EPOCH 2 - PROGRESS: at 96.22% examples, 999463 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:29,158 : INFO : EPOCH 2 - PROGRESS: at 99.26% examples, 994775 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:29,335 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:08:29,336 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:08:29,337 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:08:29,367 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:08:29,373 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:08:29,374 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:08:29,380 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:08:29,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:08:29,390 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:08:29,396 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:08:29,396 : INFO : EPOCH - 2 : training on 41519355 raw words (30345952 effective words) took 30.5s, 993951 effective words/s\n",
      "2018-10-23 14:08:30,421 : INFO : EPOCH 3 - PROGRESS: at 2.76% examples, 851157 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:31,434 : INFO : EPOCH 3 - PROGRESS: at 5.57% examples, 845698 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:32,434 : INFO : EPOCH 3 - PROGRESS: at 7.99% examples, 818295 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:33,442 : INFO : EPOCH 3 - PROGRESS: at 10.05% examples, 792042 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:34,450 : INFO : EPOCH 3 - PROGRESS: at 12.03% examples, 781902 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:35,451 : INFO : EPOCH 3 - PROGRESS: at 14.16% examples, 773850 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-23 14:08:36,474 : INFO : EPOCH 3 - PROGRESS: at 16.45% examples, 774260 words/s, in_qsize 19, out_qsize 5\n",
      "2018-10-23 14:08:37,481 : INFO : EPOCH 3 - PROGRESS: at 18.51% examples, 771336 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:38,500 : INFO : EPOCH 3 - PROGRESS: at 20.29% examples, 762003 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:39,508 : INFO : EPOCH 3 - PROGRESS: at 22.95% examples, 774754 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:40,524 : INFO : EPOCH 3 - PROGRESS: at 26.00% examples, 797303 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:08:41,549 : INFO : EPOCH 3 - PROGRESS: at 29.87% examples, 816680 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:42,562 : INFO : EPOCH 3 - PROGRESS: at 33.42% examples, 828902 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:43,569 : INFO : EPOCH 3 - PROGRESS: at 36.34% examples, 830288 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:08:44,579 : INFO : EPOCH 3 - PROGRESS: at 39.85% examples, 840964 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:45,585 : INFO : EPOCH 3 - PROGRESS: at 43.66% examples, 852791 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:46,586 : INFO : EPOCH 3 - PROGRESS: at 47.08% examples, 859282 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:47,593 : INFO : EPOCH 3 - PROGRESS: at 50.56% examples, 866428 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:48,598 : INFO : EPOCH 3 - PROGRESS: at 53.28% examples, 864881 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:49,603 : INFO : EPOCH 3 - PROGRESS: at 56.66% examples, 869405 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:08:50,609 : INFO : EPOCH 3 - PROGRESS: at 60.29% examples, 877656 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:08:51,610 : INFO : EPOCH 3 - PROGRESS: at 64.01% examples, 884955 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:52,621 : INFO : EPOCH 3 - PROGRESS: at 67.50% examples, 890875 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:53,625 : INFO : EPOCH 3 - PROGRESS: at 70.77% examples, 895583 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:54,631 : INFO : EPOCH 3 - PROGRESS: at 74.23% examples, 899022 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:08:55,634 : INFO : EPOCH 3 - PROGRESS: at 77.42% examples, 903556 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:56,639 : INFO : EPOCH 3 - PROGRESS: at 80.78% examples, 908569 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:08:57,640 : INFO : EPOCH 3 - PROGRESS: at 84.24% examples, 913341 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:08:58,641 : INFO : EPOCH 3 - PROGRESS: at 87.71% examples, 916774 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:08:59,651 : INFO : EPOCH 3 - PROGRESS: at 91.20% examples, 918897 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:00,660 : INFO : EPOCH 3 - PROGRESS: at 94.58% examples, 920850 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:01,673 : INFO : EPOCH 3 - PROGRESS: at 97.55% examples, 918707 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:02,325 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:09:02,326 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:09:02,332 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:09:02,335 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:09:02,341 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:09:02,343 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:09:02,353 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:09:02,354 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:09:02,354 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:09:02,369 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:09:02,369 : INFO : EPOCH - 3 : training on 41519355 raw words (30349800 effective words) took 33.0s, 920656 effective words/s\n",
      "2018-10-23 14:09:03,377 : INFO : EPOCH 4 - PROGRESS: at 3.24% examples, 1000880 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:04,384 : INFO : EPOCH 4 - PROGRESS: at 6.36% examples, 976319 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:09:05,386 : INFO : EPOCH 4 - PROGRESS: at 9.14% examples, 947758 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:06,391 : INFO : EPOCH 4 - PROGRESS: at 11.80% examples, 962790 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:07,414 : INFO : EPOCH 4 - PROGRESS: at 14.58% examples, 957146 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:08,430 : INFO : EPOCH 4 - PROGRESS: at 16.98% examples, 934677 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:09:09,450 : INFO : EPOCH 4 - PROGRESS: at 19.73% examples, 948085 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:10,463 : INFO : EPOCH 4 - PROGRESS: at 22.72% examples, 957143 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:11,486 : INFO : EPOCH 4 - PROGRESS: at 25.73% examples, 964133 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:12,491 : INFO : EPOCH 4 - PROGRESS: at 29.46% examples, 968919 words/s, in_qsize 19, out_qsize 1\n",
      "2018-10-23 14:09:13,504 : INFO : EPOCH 4 - PROGRESS: at 33.19% examples, 973386 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:14,516 : INFO : EPOCH 4 - PROGRESS: at 36.66% examples, 975608 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-23 14:09:15,520 : INFO : EPOCH 4 - PROGRESS: at 40.26% examples, 978264 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:16,527 : INFO : EPOCH 4 - PROGRESS: at 44.06% examples, 982558 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:17,537 : INFO : EPOCH 4 - PROGRESS: at 47.60% examples, 983115 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:18,553 : INFO : EPOCH 4 - PROGRESS: at 51.13% examples, 984628 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:19,561 : INFO : EPOCH 4 - PROGRESS: at 54.50% examples, 986384 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:20,565 : INFO : EPOCH 4 - PROGRESS: at 58.20% examples, 989930 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:21,573 : INFO : EPOCH 4 - PROGRESS: at 61.70% examples, 990717 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:22,583 : INFO : EPOCH 4 - PROGRESS: at 65.41% examples, 992278 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:23,585 : INFO : EPOCH 4 - PROGRESS: at 68.83% examples, 993482 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:24,598 : INFO : EPOCH 4 - PROGRESS: at 72.07% examples, 993617 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:09:25,600 : INFO : EPOCH 4 - PROGRESS: at 75.52% examples, 994203 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:26,627 : INFO : EPOCH 4 - PROGRESS: at 78.75% examples, 994523 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:27,634 : INFO : EPOCH 4 - PROGRESS: at 82.29% examples, 997342 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:28,635 : INFO : EPOCH 4 - PROGRESS: at 85.58% examples, 998496 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:29,639 : INFO : EPOCH 4 - PROGRESS: at 89.12% examples, 997728 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:30,643 : INFO : EPOCH 4 - PROGRESS: at 92.62% examples, 997813 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:31,643 : INFO : EPOCH 4 - PROGRESS: at 96.03% examples, 998007 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:32,655 : INFO : EPOCH 4 - PROGRESS: at 99.62% examples, 998937 words/s, in_qsize 15, out_qsize 0\n",
      "2018-10-23 14:09:32,697 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:09:32,698 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:09:32,700 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:09:32,721 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:09:32,722 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:09:32,723 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:09:32,724 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:09:32,734 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:09:32,740 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:09:32,745 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:09:32,746 : INFO : EPOCH - 4 : training on 41519355 raw words (30352757 effective words) took 30.4s, 999386 effective words/s\n",
      "2018-10-23 14:09:33,767 : INFO : EPOCH 5 - PROGRESS: at 3.27% examples, 1002413 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:09:34,790 : INFO : EPOCH 5 - PROGRESS: at 6.73% examples, 1015758 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:35,791 : INFO : EPOCH 5 - PROGRESS: at 9.79% examples, 1019013 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:36,797 : INFO : EPOCH 5 - PROGRESS: at 12.36% examples, 1007393 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:37,802 : INFO : EPOCH 5 - PROGRESS: at 15.41% examples, 1009500 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:38,817 : INFO : EPOCH 5 - PROGRESS: at 18.29% examples, 1014079 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:39,819 : INFO : EPOCH 5 - PROGRESS: at 20.92% examples, 1016454 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:40,831 : INFO : EPOCH 5 - PROGRESS: at 23.86% examples, 1015112 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:09:41,840 : INFO : EPOCH 5 - PROGRESS: at 27.41% examples, 1016742 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:42,861 : INFO : EPOCH 5 - PROGRESS: at 30.97% examples, 1011867 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:43,871 : INFO : EPOCH 5 - PROGRESS: at 34.50% examples, 1010224 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:44,879 : INFO : EPOCH 5 - PROGRESS: at 37.44% examples, 996390 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:45,892 : INFO : EPOCH 5 - PROGRESS: at 41.08% examples, 995797 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:46,902 : INFO : EPOCH 5 - PROGRESS: at 44.67% examples, 993993 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:47,908 : INFO : EPOCH 5 - PROGRESS: at 47.49% examples, 981745 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:48,914 : INFO : EPOCH 5 - PROGRESS: at 50.12% examples, 966512 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:49,953 : INFO : EPOCH 5 - PROGRESS: at 52.85% examples, 956611 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:09:50,959 : INFO : EPOCH 5 - PROGRESS: at 55.86% examples, 951340 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:51,966 : INFO : EPOCH 5 - PROGRESS: at 58.73% examples, 945144 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:52,972 : INFO : EPOCH 5 - PROGRESS: at 61.77% examples, 941873 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:53,972 : INFO : EPOCH 5 - PROGRESS: at 65.41% examples, 945006 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:09:54,974 : INFO : EPOCH 5 - PROGRESS: at 68.93% examples, 949596 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:55,982 : INFO : EPOCH 5 - PROGRESS: at 72.25% examples, 952789 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:09:56,985 : INFO : EPOCH 5 - PROGRESS: at 75.80% examples, 956463 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:58,005 : INFO : EPOCH 5 - PROGRESS: at 78.95% examples, 957640 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:09:59,017 : INFO : EPOCH 5 - PROGRESS: at 82.14% examples, 957490 words/s, in_qsize 15, out_qsize 4\n",
      "2018-10-23 14:10:00,017 : INFO : EPOCH 5 - PROGRESS: at 85.41% examples, 959799 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:01,025 : INFO : EPOCH 5 - PROGRESS: at 89.17% examples, 962612 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:02,038 : INFO : EPOCH 5 - PROGRESS: at 92.77% examples, 964823 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:03,042 : INFO : EPOCH 5 - PROGRESS: at 96.18% examples, 965976 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:04,062 : INFO : EPOCH 5 - PROGRESS: at 99.67% examples, 966502 words/s, in_qsize 13, out_qsize 0\n",
      "2018-10-23 14:10:04,085 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:10:04,105 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:10:04,108 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:10:04,113 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:10:04,114 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:10:04,116 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:10:04,117 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:10:04,118 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:10:04,125 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:10:04,134 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:10:04,135 : INFO : EPOCH - 5 : training on 41519355 raw words (30351475 effective words) took 31.4s, 967150 effective words/s\n",
      "2018-10-23 14:10:04,136 : INFO : training on a 207596775 raw words (151749294 effective words) took 157.3s, 964727 effective words/s\n",
      "2018-10-23 14:10:04,166 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-10-23 14:10:04,167 : INFO : training model with 10 workers on 70538 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-10-23 14:10:05,181 : INFO : EPOCH 1 - PROGRESS: at 3.15% examples, 966549 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:10:06,199 : INFO : EPOCH 1 - PROGRESS: at 6.59% examples, 1003756 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:07,204 : INFO : EPOCH 1 - PROGRESS: at 9.75% examples, 1014452 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:08,216 : INFO : EPOCH 1 - PROGRESS: at 12.36% examples, 1007818 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:10:09,223 : INFO : EPOCH 1 - PROGRESS: at 15.43% examples, 1010861 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:10,236 : INFO : EPOCH 1 - PROGRESS: at 17.76% examples, 983517 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:11,239 : INFO : EPOCH 1 - PROGRESS: at 20.27% examples, 979584 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:10:12,241 : INFO : EPOCH 1 - PROGRESS: at 23.28% examples, 987103 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:13,268 : INFO : EPOCH 1 - PROGRESS: at 26.55% examples, 989549 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:14,289 : INFO : EPOCH 1 - PROGRESS: at 30.21% examples, 990925 words/s, in_qsize 19, out_qsize 2\n",
      "2018-10-23 14:10:15,297 : INFO : EPOCH 1 - PROGRESS: at 33.60% examples, 986135 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:10:16,325 : INFO : EPOCH 1 - PROGRESS: at 36.63% examples, 974072 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:10:17,332 : INFO : EPOCH 1 - PROGRESS: at 39.77% examples, 967904 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:18,335 : INFO : EPOCH 1 - PROGRESS: at 42.99% examples, 961437 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:10:19,374 : INFO : EPOCH 1 - PROGRESS: at 46.35% examples, 958510 words/s, in_qsize 14, out_qsize 4\n",
      "2018-10-23 14:10:20,344 : INFO : EPOCH 1 - PROGRESS: at 49.85% examples, 961888 words/s, in_qsize 19, out_qsize 1\n",
      "2018-10-23 14:10:21,364 : INFO : EPOCH 1 - PROGRESS: at 52.85% examples, 957035 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:10:22,365 : INFO : EPOCH 1 - PROGRESS: at 55.96% examples, 953692 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:23,369 : INFO : EPOCH 1 - PROGRESS: at 59.10% examples, 951227 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:24,381 : INFO : EPOCH 1 - PROGRESS: at 62.55% examples, 953419 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:25,386 : INFO : EPOCH 1 - PROGRESS: at 65.89% examples, 952743 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:26,402 : INFO : EPOCH 1 - PROGRESS: at 68.94% examples, 949539 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:27,405 : INFO : EPOCH 1 - PROGRESS: at 72.28% examples, 952955 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:28,417 : INFO : EPOCH 1 - PROGRESS: at 75.81% examples, 956210 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:29,451 : INFO : EPOCH 1 - PROGRESS: at 78.88% examples, 955751 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:30,455 : INFO : EPOCH 1 - PROGRESS: at 82.33% examples, 958982 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:31,466 : INFO : EPOCH 1 - PROGRESS: at 85.70% examples, 961653 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:32,466 : INFO : EPOCH 1 - PROGRESS: at 89.26% examples, 962600 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:33,477 : INFO : EPOCH 1 - PROGRESS: at 92.53% examples, 961436 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:34,482 : INFO : EPOCH 1 - PROGRESS: at 95.95% examples, 962694 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:35,485 : INFO : EPOCH 1 - PROGRESS: at 99.31% examples, 962928 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:35,630 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:10:35,639 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:10:35,651 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:10:35,652 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:10:35,657 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:10:35,657 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:10:35,663 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:10:35,667 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:10:35,669 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:10:35,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:10:35,677 : INFO : EPOCH - 1 : training on 41519355 raw words (30348084 effective words) took 31.5s, 963334 effective words/s\n",
      "2018-10-23 14:10:36,688 : INFO : EPOCH 2 - PROGRESS: at 2.79% examples, 869032 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:37,691 : INFO : EPOCH 2 - PROGRESS: at 6.28% examples, 965951 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:38,697 : INFO : EPOCH 2 - PROGRESS: at 9.40% examples, 975148 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:10:39,697 : INFO : EPOCH 2 - PROGRESS: at 12.03% examples, 982523 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:40,705 : INFO : EPOCH 2 - PROGRESS: at 14.92% examples, 984625 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:41,710 : INFO : EPOCH 2 - PROGRESS: at 17.89% examples, 996383 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:42,715 : INFO : EPOCH 2 - PROGRESS: at 20.55% examples, 1000759 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:43,715 : INFO : EPOCH 2 - PROGRESS: at 23.52% examples, 1003814 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:44,742 : INFO : EPOCH 2 - PROGRESS: at 26.84% examples, 1002998 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:45,774 : INFO : EPOCH 2 - PROGRESS: at 30.64% examples, 1004797 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:10:46,779 : INFO : EPOCH 2 - PROGRESS: at 34.18% examples, 1004260 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:47,806 : INFO : EPOCH 2 - PROGRESS: at 37.60% examples, 1000002 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:48,806 : INFO : EPOCH 2 - PROGRESS: at 41.24% examples, 1000114 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:49,817 : INFO : EPOCH 2 - PROGRESS: at 44.99% examples, 1001008 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:50,827 : INFO : EPOCH 2 - PROGRESS: at 48.32% examples, 998445 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:51,847 : INFO : EPOCH 2 - PROGRESS: at 51.21% examples, 986680 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:52,857 : INFO : EPOCH 2 - PROGRESS: at 54.56% examples, 988215 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:53,863 : INFO : EPOCH 2 - PROGRESS: at 58.23% examples, 990745 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:10:54,865 : INFO : EPOCH 2 - PROGRESS: at 61.79% examples, 992975 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:10:55,867 : INFO : EPOCH 2 - PROGRESS: at 65.43% examples, 993700 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:10:56,873 : INFO : EPOCH 2 - PROGRESS: at 68.87% examples, 994995 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:57,873 : INFO : EPOCH 2 - PROGRESS: at 72.13% examples, 995636 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:58,877 : INFO : EPOCH 2 - PROGRESS: at 75.63% examples, 996942 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:10:59,884 : INFO : EPOCH 2 - PROGRESS: at 78.87% examples, 997877 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:11:00,892 : INFO : EPOCH 2 - PROGRESS: at 82.39% examples, 1000552 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:01,897 : INFO : EPOCH 2 - PROGRESS: at 85.61% examples, 1000281 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:02,902 : INFO : EPOCH 2 - PROGRESS: at 89.31% examples, 1001046 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:03,904 : INFO : EPOCH 2 - PROGRESS: at 92.74% examples, 1000517 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:04,905 : INFO : EPOCH 2 - PROGRESS: at 96.38% examples, 1002865 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:05,851 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:11:05,878 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:11:05,883 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:11:05,884 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:11:05,887 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:11:05,907 : INFO : EPOCH 2 - PROGRESS: at 99.90% examples, 1003205 words/s, in_qsize 4, out_qsize 1\n",
      "2018-10-23 14:11:05,908 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:11:05,912 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:11:05,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:11:05,920 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:11:05,922 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:11:05,923 : INFO : EPOCH - 2 : training on 41519355 raw words (30346129 effective words) took 30.2s, 1003546 effective words/s\n",
      "2018-10-23 14:11:06,938 : INFO : EPOCH 3 - PROGRESS: at 3.27% examples, 1007956 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:07,955 : INFO : EPOCH 3 - PROGRESS: at 6.55% examples, 996478 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:08,965 : INFO : EPOCH 3 - PROGRESS: at 9.28% examples, 953988 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:09,984 : INFO : EPOCH 3 - PROGRESS: at 11.56% examples, 927382 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:10,999 : INFO : EPOCH 3 - PROGRESS: at 14.00% examples, 913199 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:12,002 : INFO : EPOCH 3 - PROGRESS: at 16.96% examples, 930945 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:13,004 : INFO : EPOCH 3 - PROGRESS: at 19.72% examples, 947277 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:14,014 : INFO : EPOCH 3 - PROGRESS: at 22.61% examples, 953118 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:11:15,016 : INFO : EPOCH 3 - PROGRESS: at 24.40% examples, 925628 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:16,038 : INFO : EPOCH 3 - PROGRESS: at 27.14% examples, 906256 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:17,039 : INFO : EPOCH 3 - PROGRESS: at 29.90% examples, 893331 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:18,070 : INFO : EPOCH 3 - PROGRESS: at 33.17% examples, 892316 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:19,100 : INFO : EPOCH 3 - PROGRESS: at 36.01% examples, 886347 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:20,109 : INFO : EPOCH 3 - PROGRESS: at 38.78% examples, 877469 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:21,130 : INFO : EPOCH 3 - PROGRESS: at 41.63% examples, 869858 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:22,130 : INFO : EPOCH 3 - PROGRESS: at 44.49% examples, 865048 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:23,151 : INFO : EPOCH 3 - PROGRESS: at 46.93% examples, 854747 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:24,154 : INFO : EPOCH 3 - PROGRESS: at 49.49% examples, 847255 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:25,162 : INFO : EPOCH 3 - PROGRESS: at 52.80% examples, 854464 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:26,169 : INFO : EPOCH 3 - PROGRESS: at 55.71% examples, 854047 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:27,171 : INFO : EPOCH 3 - PROGRESS: at 58.97% examples, 857933 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:28,175 : INFO : EPOCH 3 - PROGRESS: at 61.88% examples, 857675 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:29,193 : INFO : EPOCH 3 - PROGRESS: at 65.03% examples, 856380 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:30,199 : INFO : EPOCH 3 - PROGRESS: at 67.57% examples, 853069 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:31,207 : INFO : EPOCH 3 - PROGRESS: at 70.68% examples, 856688 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:11:32,222 : INFO : EPOCH 3 - PROGRESS: at 73.35% examples, 852940 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:33,233 : INFO : EPOCH 3 - PROGRESS: at 75.72% examples, 848027 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:34,240 : INFO : EPOCH 3 - PROGRESS: at 78.23% examples, 846318 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:35,263 : INFO : EPOCH 3 - PROGRESS: at 80.62% examples, 841846 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:36,270 : INFO : EPOCH 3 - PROGRESS: at 83.10% examples, 838120 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:37,279 : INFO : EPOCH 3 - PROGRESS: at 85.10% examples, 831529 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:38,280 : INFO : EPOCH 3 - PROGRESS: at 88.15% examples, 832304 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:39,291 : INFO : EPOCH 3 - PROGRESS: at 92.16% examples, 841099 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:11:40,298 : INFO : EPOCH 3 - PROGRESS: at 95.30% examples, 843546 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:41,302 : INFO : EPOCH 3 - PROGRESS: at 98.14% examples, 843215 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:41,807 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:11:41,829 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:11:41,834 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:11:41,837 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:11:41,841 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:11:41,843 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:11:41,853 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:11:41,863 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:11:41,874 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:11:41,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:11:41,878 : INFO : EPOCH - 3 : training on 41519355 raw words (30350534 effective words) took 35.9s, 844277 effective words/s\n",
      "2018-10-23 14:11:42,889 : INFO : EPOCH 4 - PROGRESS: at 2.12% examples, 662547 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:43,896 : INFO : EPOCH 4 - PROGRESS: at 4.34% examples, 664732 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:44,943 : INFO : EPOCH 4 - PROGRESS: at 6.55% examples, 660506 words/s, in_qsize 18, out_qsize 4\n",
      "2018-10-23 14:11:45,948 : INFO : EPOCH 4 - PROGRESS: at 8.74% examples, 667072 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-23 14:11:46,948 : INFO : EPOCH 4 - PROGRESS: at 10.68% examples, 675856 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:47,955 : INFO : EPOCH 4 - PROGRESS: at 12.38% examples, 673911 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:48,964 : INFO : EPOCH 4 - PROGRESS: at 14.65% examples, 684597 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:49,979 : INFO : EPOCH 4 - PROGRESS: at 17.53% examples, 726348 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:50,989 : INFO : EPOCH 4 - PROGRESS: at 20.57% examples, 774249 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:51,989 : INFO : EPOCH 4 - PROGRESS: at 23.63% examples, 802065 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:11:52,998 : INFO : EPOCH 4 - PROGRESS: at 26.47% examples, 808272 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:53,999 : INFO : EPOCH 4 - PROGRESS: at 29.93% examples, 820746 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:54,999 : INFO : EPOCH 4 - PROGRESS: at 33.27% examples, 828536 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:56,008 : INFO : EPOCH 4 - PROGRESS: at 36.46% examples, 834822 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:57,055 : INFO : EPOCH 4 - PROGRESS: at 39.45% examples, 832783 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:11:58,069 : INFO : EPOCH 4 - PROGRESS: at 43.04% examples, 842460 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:11:59,099 : INFO : EPOCH 4 - PROGRESS: at 45.70% examples, 833553 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:00,116 : INFO : EPOCH 4 - PROGRESS: at 48.59% examples, 833709 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:01,156 : INFO : EPOCH 4 - PROGRESS: at 51.93% examples, 838712 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:12:02,162 : INFO : EPOCH 4 - PROGRESS: at 54.33% examples, 834058 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:03,162 : INFO : EPOCH 4 - PROGRESS: at 57.99% examples, 843736 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:04,169 : INFO : EPOCH 4 - PROGRESS: at 61.76% examples, 854739 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:05,175 : INFO : EPOCH 4 - PROGRESS: at 65.46% examples, 861787 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:12:06,189 : INFO : EPOCH 4 - PROGRESS: at 69.22% examples, 872178 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:07,202 : INFO : EPOCH 4 - PROGRESS: at 73.06% examples, 883118 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:08,213 : INFO : EPOCH 4 - PROGRESS: at 75.68% examples, 879083 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:09,215 : INFO : EPOCH 4 - PROGRESS: at 78.56% examples, 880257 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:10,217 : INFO : EPOCH 4 - PROGRESS: at 81.14% examples, 877342 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:11,238 : INFO : EPOCH 4 - PROGRESS: at 84.36% examples, 880174 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:12,239 : INFO : EPOCH 4 - PROGRESS: at 87.38% examples, 880293 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:13,245 : INFO : EPOCH 4 - PROGRESS: at 90.42% examples, 879236 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:14,274 : INFO : EPOCH 4 - PROGRESS: at 92.88% examples, 873601 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:15,288 : INFO : EPOCH 4 - PROGRESS: at 94.81% examples, 863942 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:16,302 : INFO : EPOCH 4 - PROGRESS: at 96.89% examples, 856077 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:12:17,388 : INFO : EPOCH 4 - PROGRESS: at 98.94% examples, 846340 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:17,849 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:12:17,870 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:12:17,881 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:12:17,902 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:12:17,912 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:12:17,918 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:12:17,920 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:12:17,930 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:12:17,932 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:12:17,936 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:12:17,937 : INFO : EPOCH - 4 : training on 41519355 raw words (30352364 effective words) took 36.0s, 841962 effective words/s\n",
      "2018-10-23 14:12:18,957 : INFO : EPOCH 5 - PROGRESS: at 2.04% examples, 642349 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:19,959 : INFO : EPOCH 5 - PROGRESS: at 4.04% examples, 623762 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:20,969 : INFO : EPOCH 5 - PROGRESS: at 6.79% examples, 694283 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:22,000 : INFO : EPOCH 5 - PROGRESS: at 9.41% examples, 728892 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-23 14:12:23,066 : INFO : EPOCH 5 - PROGRESS: at 11.36% examples, 718823 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:24,067 : INFO : EPOCH 5 - PROGRESS: at 14.24% examples, 770615 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:25,073 : INFO : EPOCH 5 - PROGRESS: at 16.42% examples, 767089 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:26,077 : INFO : EPOCH 5 - PROGRESS: at 18.14% examples, 751132 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:27,122 : INFO : EPOCH 5 - PROGRESS: at 20.37% examples, 758445 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:12:28,125 : INFO : EPOCH 5 - PROGRESS: at 22.53% examples, 754838 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:29,175 : INFO : EPOCH 5 - PROGRESS: at 24.04% examples, 737442 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:30,192 : INFO : EPOCH 5 - PROGRESS: at 26.61% examples, 736832 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:12:31,197 : INFO : EPOCH 5 - PROGRESS: at 29.37% examples, 738039 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:12:32,217 : INFO : EPOCH 5 - PROGRESS: at 31.76% examples, 730872 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:33,233 : INFO : EPOCH 5 - PROGRESS: at 34.85% examples, 742333 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:34,248 : INFO : EPOCH 5 - PROGRESS: at 38.70% examples, 762371 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:35,298 : INFO : EPOCH 5 - PROGRESS: at 40.63% examples, 748181 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:12:36,305 : INFO : EPOCH 5 - PROGRESS: at 43.11% examples, 743652 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:37,313 : INFO : EPOCH 5 - PROGRESS: at 46.00% examples, 745572 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:38,322 : INFO : EPOCH 5 - PROGRESS: at 49.68% examples, 761352 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:39,386 : INFO : EPOCH 5 - PROGRESS: at 52.90% examples, 768838 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:12:40,388 : INFO : EPOCH 5 - PROGRESS: at 55.80% examples, 771542 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:12:41,404 : INFO : EPOCH 5 - PROGRESS: at 57.67% examples, 761275 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:12:42,563 : INFO : EPOCH 5 - PROGRESS: at 60.48% examples, 758633 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:12:43,571 : INFO : EPOCH 5 - PROGRESS: at 63.73% examples, 764356 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:44,584 : INFO : EPOCH 5 - PROGRESS: at 66.51% examples, 766009 words/s, in_qsize 13, out_qsize 6\n",
      "2018-10-23 14:12:45,586 : INFO : EPOCH 5 - PROGRESS: at 70.43% examples, 781192 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:12:46,600 : INFO : EPOCH 5 - PROGRESS: at 73.19% examples, 781748 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:47,603 : INFO : EPOCH 5 - PROGRESS: at 74.80% examples, 770855 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:12:48,619 : INFO : EPOCH 5 - PROGRESS: at 76.69% examples, 765282 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:49,627 : INFO : EPOCH 5 - PROGRESS: at 78.94% examples, 763399 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:12:50,634 : INFO : EPOCH 5 - PROGRESS: at 81.61% examples, 764999 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:51,638 : INFO : EPOCH 5 - PROGRESS: at 83.95% examples, 762936 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:52,786 : INFO : EPOCH 5 - PROGRESS: at 86.56% examples, 760480 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:53,796 : INFO : EPOCH 5 - PROGRESS: at 90.21% examples, 767472 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:12:54,819 : INFO : EPOCH 5 - PROGRESS: at 94.13% examples, 777286 words/s, in_qsize 15, out_qsize 4\n",
      "2018-10-23 14:12:55,824 : INFO : EPOCH 5 - PROGRESS: at 97.31% examples, 781029 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:12:56,547 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:12:56,552 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:12:56,579 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:12:56,580 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:12:56,593 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:12:56,594 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:12:56,595 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:12:56,596 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:12:56,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:12:56,614 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:12:56,614 : INFO : EPOCH - 5 : training on 41519355 raw words (30350190 effective words) took 38.7s, 785119 effective words/s\n",
      "2018-10-23 14:12:57,627 : INFO : EPOCH 6 - PROGRESS: at 3.05% examples, 938477 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:58,642 : INFO : EPOCH 6 - PROGRESS: at 5.14% examples, 784649 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:12:59,649 : INFO : EPOCH 6 - PROGRESS: at 7.85% examples, 801488 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:13:00,671 : INFO : EPOCH 6 - PROGRESS: at 10.27% examples, 810524 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:01,679 : INFO : EPOCH 6 - PROGRESS: at 12.18% examples, 792495 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:02,682 : INFO : EPOCH 6 - PROGRESS: at 15.13% examples, 827738 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:03,682 : INFO : EPOCH 6 - PROGRESS: at 17.63% examples, 837264 words/s, in_qsize 16, out_qsize 2\n",
      "2018-10-23 14:13:04,695 : INFO : EPOCH 6 - PROGRESS: at 20.36% examples, 860814 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:13:05,705 : INFO : EPOCH 6 - PROGRESS: at 23.38% examples, 881299 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:13:06,715 : INFO : EPOCH 6 - PROGRESS: at 25.58% examples, 866448 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:07,724 : INFO : EPOCH 6 - PROGRESS: at 29.58% examples, 885832 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:08,740 : INFO : EPOCH 6 - PROGRESS: at 33.58% examples, 903793 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:13:09,744 : INFO : EPOCH 6 - PROGRESS: at 37.45% examples, 920492 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:10,769 : INFO : EPOCH 6 - PROGRESS: at 41.58% examples, 933280 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:11,792 : INFO : EPOCH 6 - PROGRESS: at 44.46% examples, 923068 words/s, in_qsize 20, out_qsize 2\n",
      "2018-10-23 14:13:12,797 : INFO : EPOCH 6 - PROGRESS: at 47.96% examples, 928046 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:13,832 : INFO : EPOCH 6 - PROGRESS: at 51.55% examples, 932396 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:13:14,865 : INFO : EPOCH 6 - PROGRESS: at 53.69% examples, 915891 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:15,878 : INFO : EPOCH 6 - PROGRESS: at 56.93% examples, 915458 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:16,881 : INFO : EPOCH 6 - PROGRESS: at 59.89% examples, 912581 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:13:17,896 : INFO : EPOCH 6 - PROGRESS: at 62.70% examples, 907482 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:18,941 : INFO : EPOCH 6 - PROGRESS: at 65.92% examples, 905665 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:19,945 : INFO : EPOCH 6 - PROGRESS: at 69.21% examples, 908547 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:20,948 : INFO : EPOCH 6 - PROGRESS: at 71.95% examples, 906340 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:13:21,976 : INFO : EPOCH 6 - PROGRESS: at 74.98% examples, 903691 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:13:22,976 : INFO : EPOCH 6 - PROGRESS: at 77.59% examples, 901349 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:24,004 : INFO : EPOCH 6 - PROGRESS: at 80.26% examples, 897489 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:25,007 : INFO : EPOCH 6 - PROGRESS: at 82.87% examples, 893416 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:26,020 : INFO : EPOCH 6 - PROGRESS: at 85.23% examples, 887783 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:13:27,033 : INFO : EPOCH 6 - PROGRESS: at 87.89% examples, 882628 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:28,072 : INFO : EPOCH 6 - PROGRESS: at 90.46% examples, 876928 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:13:29,094 : INFO : EPOCH 6 - PROGRESS: at 92.12% examples, 863772 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:30,095 : INFO : EPOCH 6 - PROGRESS: at 94.92% examples, 862736 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:31,101 : INFO : EPOCH 6 - PROGRESS: at 97.30% examples, 857610 words/s, in_qsize 16, out_qsize 4\n",
      "2018-10-23 14:13:32,114 : INFO : EPOCH 6 - PROGRESS: at 99.55% examples, 851457 words/s, in_qsize 17, out_qsize 1\n",
      "2018-10-23 14:13:32,177 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:13:32,191 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:13:32,215 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:13:32,223 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:13:32,233 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:13:32,239 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:13:32,253 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:13:32,254 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:13:32,259 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:13:32,273 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:13:32,274 : INFO : EPOCH - 6 : training on 41519355 raw words (30347216 effective words) took 35.7s, 851157 effective words/s\n",
      "2018-10-23 14:13:33,288 : INFO : EPOCH 7 - PROGRESS: at 2.02% examples, 630640 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:34,307 : INFO : EPOCH 7 - PROGRESS: at 4.63% examples, 705642 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:13:35,311 : INFO : EPOCH 7 - PROGRESS: at 7.62% examples, 777623 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:36,314 : INFO : EPOCH 7 - PROGRESS: at 10.93% examples, 871350 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:37,325 : INFO : EPOCH 7 - PROGRESS: at 12.77% examples, 836343 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:13:38,334 : INFO : EPOCH 7 - PROGRESS: at 14.94% examples, 818259 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:39,384 : INFO : EPOCH 7 - PROGRESS: at 16.53% examples, 774645 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:40,457 : INFO : EPOCH 7 - PROGRESS: at 18.81% examples, 775877 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:13:41,540 : INFO : EPOCH 7 - PROGRESS: at 20.70% examples, 766364 words/s, in_qsize 18, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:13:42,545 : INFO : EPOCH 7 - PROGRESS: at 23.42% examples, 782260 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:43,554 : INFO : EPOCH 7 - PROGRESS: at 26.07% examples, 786850 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:44,563 : INFO : EPOCH 7 - PROGRESS: at 29.08% examples, 788665 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:45,564 : INFO : EPOCH 7 - PROGRESS: at 33.05% examples, 812776 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:46,569 : INFO : EPOCH 7 - PROGRESS: at 36.77% examples, 831451 words/s, in_qsize 18, out_qsize 0\n",
      "2018-10-23 14:13:47,577 : INFO : EPOCH 7 - PROGRESS: at 41.00% examples, 854420 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:48,630 : INFO : EPOCH 7 - PROGRESS: at 43.75% examples, 845198 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:13:49,636 : INFO : EPOCH 7 - PROGRESS: at 46.01% examples, 831905 words/s, in_qsize 18, out_qsize 0\n",
      "2018-10-23 14:13:50,649 : INFO : EPOCH 7 - PROGRESS: at 48.75% examples, 829526 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:13:51,652 : INFO : EPOCH 7 - PROGRESS: at 51.61% examples, 829249 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:52,659 : INFO : EPOCH 7 - PROGRESS: at 55.37% examples, 843079 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:53,665 : INFO : EPOCH 7 - PROGRESS: at 59.28% examples, 856496 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:54,670 : INFO : EPOCH 7 - PROGRESS: at 62.60% examples, 861401 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:13:55,681 : INFO : EPOCH 7 - PROGRESS: at 65.11% examples, 852535 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:13:56,683 : INFO : EPOCH 7 - PROGRESS: at 67.83% examples, 851355 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:13:57,698 : INFO : EPOCH 7 - PROGRESS: at 71.45% examples, 860986 words/s, in_qsize 14, out_qsize 5\n",
      "2018-10-23 14:13:58,719 : INFO : EPOCH 7 - PROGRESS: at 75.49% examples, 873111 words/s, in_qsize 19, out_qsize 4\n",
      "2018-10-23 14:13:59,731 : INFO : EPOCH 7 - PROGRESS: at 79.31% examples, 884809 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:00,734 : INFO : EPOCH 7 - PROGRESS: at 83.22% examples, 894865 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:01,748 : INFO : EPOCH 7 - PROGRESS: at 87.28% examples, 905567 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:14:02,755 : INFO : EPOCH 7 - PROGRESS: at 91.51% examples, 914754 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:03,760 : INFO : EPOCH 7 - PROGRESS: at 95.57% examples, 923126 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:04,764 : INFO : EPOCH 7 - PROGRESS: at 99.51% examples, 930084 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:04,814 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:14:04,829 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:14:04,835 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:14:04,847 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:14:04,853 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:14:04,860 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:14:04,865 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:14:04,866 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:14:04,869 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:14:04,870 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:14:04,871 : INFO : EPOCH - 7 : training on 41519355 raw words (30344808 effective words) took 32.6s, 931111 effective words/s\n",
      "2018-10-23 14:14:05,885 : INFO : EPOCH 8 - PROGRESS: at 3.78% examples, 1159725 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:06,897 : INFO : EPOCH 8 - PROGRESS: at 7.59% examples, 1163023 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:07,914 : INFO : EPOCH 8 - PROGRESS: at 10.85% examples, 1150030 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:08,914 : INFO : EPOCH 8 - PROGRESS: at 14.08% examples, 1152025 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:09,916 : INFO : EPOCH 8 - PROGRESS: at 17.35% examples, 1153619 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:10,937 : INFO : EPOCH 8 - PROGRESS: at 20.44% examples, 1152057 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:11,945 : INFO : EPOCH 8 - PROGRESS: at 23.83% examples, 1158327 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:12,959 : INFO : EPOCH 8 - PROGRESS: at 27.93% examples, 1159332 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:14,000 : INFO : EPOCH 8 - PROGRESS: at 30.48% examples, 1106906 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:15,007 : INFO : EPOCH 8 - PROGRESS: at 33.10% examples, 1066590 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:16,016 : INFO : EPOCH 8 - PROGRESS: at 36.17% examples, 1051195 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:17,026 : INFO : EPOCH 8 - PROGRESS: at 39.99% examples, 1053279 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:18,028 : INFO : EPOCH 8 - PROGRESS: at 44.33% examples, 1062378 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:14:19,041 : INFO : EPOCH 8 - PROGRESS: at 47.73% examples, 1055613 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-23 14:14:20,044 : INFO : EPOCH 8 - PROGRESS: at 50.16% examples, 1030884 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:21,056 : INFO : EPOCH 8 - PROGRESS: at 52.28% examples, 1005948 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:22,083 : INFO : EPOCH 8 - PROGRESS: at 54.89% examples, 992047 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:23,101 : INFO : EPOCH 8 - PROGRESS: at 58.01% examples, 985373 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:24,131 : INFO : EPOCH 8 - PROGRESS: at 61.85% examples, 990598 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:25,148 : INFO : EPOCH 8 - PROGRESS: at 65.13% examples, 984633 words/s, in_qsize 19, out_qsize 1\n",
      "2018-10-23 14:14:26,150 : INFO : EPOCH 8 - PROGRESS: at 67.85% examples, 977039 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:27,160 : INFO : EPOCH 8 - PROGRESS: at 69.88% examples, 960495 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:28,184 : INFO : EPOCH 8 - PROGRESS: at 71.56% examples, 940626 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:29,198 : INFO : EPOCH 8 - PROGRESS: at 73.71% examples, 926293 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:30,208 : INFO : EPOCH 8 - PROGRESS: at 75.79% examples, 914974 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:31,217 : INFO : EPOCH 8 - PROGRESS: at 78.40% examples, 911628 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:14:32,231 : INFO : EPOCH 8 - PROGRESS: at 81.58% examples, 913592 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:33,239 : INFO : EPOCH 8 - PROGRESS: at 84.74% examples, 915087 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:34,249 : INFO : EPOCH 8 - PROGRESS: at 88.43% examples, 919414 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:35,256 : INFO : EPOCH 8 - PROGRESS: at 92.30% examples, 925093 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:14:36,260 : INFO : EPOCH 8 - PROGRESS: at 95.77% examples, 928175 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:37,275 : INFO : EPOCH 8 - PROGRESS: at 99.46% examples, 932247 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:37,333 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:14:37,341 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:14:37,357 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:14:37,372 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:14:37,377 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:14:37,381 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:14:37,383 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:14:37,388 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:14:37,389 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:14:37,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:14:37,394 : INFO : EPOCH - 8 : training on 41519355 raw words (30349972 effective words) took 32.5s, 933340 effective words/s\n",
      "2018-10-23 14:14:38,418 : INFO : EPOCH 9 - PROGRESS: at 3.48% examples, 1062297 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:39,419 : INFO : EPOCH 9 - PROGRESS: at 6.95% examples, 1059707 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:40,468 : INFO : EPOCH 9 - PROGRESS: at 10.17% examples, 1058212 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:14:41,476 : INFO : EPOCH 9 - PROGRESS: at 11.96% examples, 962333 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:42,489 : INFO : EPOCH 9 - PROGRESS: at 14.10% examples, 915008 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:43,494 : INFO : EPOCH 9 - PROGRESS: at 16.74% examples, 915465 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:44,497 : INFO : EPOCH 9 - PROGRESS: at 19.64% examples, 940058 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:45,508 : INFO : EPOCH 9 - PROGRESS: at 22.93% examples, 964274 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:46,509 : INFO : EPOCH 9 - PROGRESS: at 25.96% examples, 970590 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:47,514 : INFO : EPOCH 9 - PROGRESS: at 30.19% examples, 990439 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:48,514 : INFO : EPOCH 9 - PROGRESS: at 34.39% examples, 1007160 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:14:49,531 : INFO : EPOCH 9 - PROGRESS: at 38.31% examples, 1014803 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:14:50,540 : INFO : EPOCH 9 - PROGRESS: at 42.34% examples, 1021865 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:51,595 : INFO : EPOCH 9 - PROGRESS: at 46.12% examples, 1018590 words/s, in_qsize 13, out_qsize 6\n",
      "2018-10-23 14:14:52,597 : INFO : EPOCH 9 - PROGRESS: at 49.73% examples, 1021060 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:53,608 : INFO : EPOCH 9 - PROGRESS: at 53.37% examples, 1025696 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-23 14:14:54,614 : INFO : EPOCH 9 - PROGRESS: at 57.55% examples, 1034259 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:55,627 : INFO : EPOCH 9 - PROGRESS: at 61.04% examples, 1032373 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:56,633 : INFO : EPOCH 9 - PROGRESS: at 64.84% examples, 1032761 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:14:57,643 : INFO : EPOCH 9 - PROGRESS: at 68.19% examples, 1031623 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:14:58,650 : INFO : EPOCH 9 - PROGRESS: at 71.61% examples, 1032217 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:14:59,660 : INFO : EPOCH 9 - PROGRESS: at 75.13% examples, 1031618 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:15:00,661 : INFO : EPOCH 9 - PROGRESS: at 78.63% examples, 1034895 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:01,664 : INFO : EPOCH 9 - PROGRESS: at 82.30% examples, 1038421 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:15:02,684 : INFO : EPOCH 9 - PROGRESS: at 85.80% examples, 1039194 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:03,724 : INFO : EPOCH 9 - PROGRESS: at 88.81% examples, 1029663 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:04,727 : INFO : EPOCH 9 - PROGRESS: at 91.44% examples, 1019366 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:15:05,736 : INFO : EPOCH 9 - PROGRESS: at 94.43% examples, 1014119 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:15:06,744 : INFO : EPOCH 9 - PROGRESS: at 97.72% examples, 1012179 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:07,347 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:15:07,349 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:15:07,367 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-23 14:15:07,374 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:15:07,390 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:15:07,391 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:15:07,394 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:15:07,395 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:15:07,397 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:15:07,402 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:15:07,403 : INFO : EPOCH - 9 : training on 41519355 raw words (30347640 effective words) took 30.0s, 1011492 effective words/s\n",
      "2018-10-23 14:15:08,416 : INFO : EPOCH 10 - PROGRESS: at 2.53% examples, 786715 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:09,433 : INFO : EPOCH 10 - PROGRESS: at 5.69% examples, 865021 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:15:10,440 : INFO : EPOCH 10 - PROGRESS: at 9.27% examples, 954891 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:11,466 : INFO : EPOCH 10 - PROGRESS: at 11.48% examples, 917031 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:12,497 : INFO : EPOCH 10 - PROGRESS: at 13.96% examples, 906354 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:15:13,499 : INFO : EPOCH 10 - PROGRESS: at 16.84% examples, 919343 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:14,507 : INFO : EPOCH 10 - PROGRESS: at 19.31% examples, 921401 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:15:15,509 : INFO : EPOCH 10 - PROGRESS: at 22.21% examples, 931175 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:16,525 : INFO : EPOCH 10 - PROGRESS: at 24.70% examples, 933163 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-23 14:15:17,544 : INFO : EPOCH 10 - PROGRESS: at 29.08% examples, 956204 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:18,547 : INFO : EPOCH 10 - PROGRESS: at 33.30% examples, 975541 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:19,548 : INFO : EPOCH 10 - PROGRESS: at 37.15% examples, 988554 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:20,557 : INFO : EPOCH 10 - PROGRESS: at 41.16% examples, 996592 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:15:21,560 : INFO : EPOCH 10 - PROGRESS: at 44.81% examples, 996200 words/s, in_qsize 15, out_qsize 4\n",
      "2018-10-23 14:15:22,564 : INFO : EPOCH 10 - PROGRESS: at 48.00% examples, 991568 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:15:23,572 : INFO : EPOCH 10 - PROGRESS: at 51.38% examples, 989852 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:24,576 : INFO : EPOCH 10 - PROGRESS: at 54.68% examples, 990745 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:25,589 : INFO : EPOCH 10 - PROGRESS: at 58.17% examples, 989880 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-23 14:15:26,590 : INFO : EPOCH 10 - PROGRESS: at 61.30% examples, 985129 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:27,597 : INFO : EPOCH 10 - PROGRESS: at 64.34% examples, 977136 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:28,599 : INFO : EPOCH 10 - PROGRESS: at 67.50% examples, 975929 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:29,600 : INFO : EPOCH 10 - PROGRESS: at 70.99% examples, 980628 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-23 14:15:30,639 : INFO : EPOCH 10 - PROGRESS: at 74.42% examples, 980401 words/s, in_qsize 14, out_qsize 4\n",
      "2018-10-23 14:15:31,605 : INFO : EPOCH 10 - PROGRESS: at 77.53% examples, 980922 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:32,621 : INFO : EPOCH 10 - PROGRESS: at 81.16% examples, 986260 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:33,631 : INFO : EPOCH 10 - PROGRESS: at 85.02% examples, 993212 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-23 14:15:34,660 : INFO : EPOCH 10 - PROGRESS: at 89.22% examples, 999163 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:35,684 : INFO : EPOCH 10 - PROGRESS: at 92.21% examples, 992896 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-23 14:15:36,692 : INFO : EPOCH 10 - PROGRESS: at 94.97% examples, 986783 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:37,695 : INFO : EPOCH 10 - PROGRESS: at 98.17% examples, 985029 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-23 14:15:38,105 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-23 14:15:38,106 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-23 14:15:38,108 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:15:38,108 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-23 14:15:38,121 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-23 14:15:38,132 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-23 14:15:38,137 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-23 14:15:38,138 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-23 14:15:38,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-23 14:15:38,144 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-23 14:15:38,145 : INFO : EPOCH - 10 : training on 41519355 raw words (30350398 effective words) took 30.7s, 987432 effective words/s\n",
      "2018-10-23 14:15:38,145 : INFO : training on a 415193550 raw words (303487335 effective words) took 334.0s, 908713 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(303487335, 415193550)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10, sg=0)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's look at some output \n",
    "This first example shows a simple case of looking up words similar to the word `dirty`. All we need to do here is to call the `most_similar` function and provide the word `dirty` as the positive example. This returns the top 10 similar words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 14:03:11,925 : INFO : precomputing L2-norms of word weight vectors\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.8682507276535034),\n",
       " ('unclean', 0.7850955128669739),\n",
       " ('stained', 0.7723395228385925),\n",
       " ('smelly', 0.7694259881973267),\n",
       " ('grubby', 0.7430247068405151),\n",
       " ('dingy', 0.7430081367492676),\n",
       " ('dusty', 0.7368177175521851),\n",
       " ('grimy', 0.7159562110900879),\n",
       " ('gross', 0.7135449051856995),\n",
       " ('disgusting', 0.7100102305412292)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w1 = \"dirty\"\n",
    "model.wv.most_similar (positive=w1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good, right? Let's look at a few more. Let's look at similarity for `polite`, `france` and `shocked`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.9182709455490112),\n",
       " ('friendly', 0.8322016596794128),\n",
       " ('cordial', 0.7941110134124756),\n",
       " ('professional', 0.7878994345664978),\n",
       " ('curteous', 0.7710005640983582),\n",
       " ('attentive', 0.7694741487503052)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'polite'\n",
    "w1 = [\"polite\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('canada', 0.6381232738494873),\n",
       " ('germany', 0.6306766271591187),\n",
       " ('spain', 0.5974881052970886),\n",
       " ('austria', 0.595977783203125),\n",
       " ('philadelphia', 0.5831947922706604),\n",
       " ('mexico', 0.5786791443824768)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'france'\n",
    "w1 = [\"france\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('horrified', 0.8097331523895264),\n",
       " ('amazed', 0.7879684567451477),\n",
       " ('astonished', 0.7564995884895325),\n",
       " ('stunned', 0.7542758584022522),\n",
       " ('dismayed', 0.7537792921066284),\n",
       " ('appalled', 0.7423660159111023)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'shocked'\n",
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's, nice. You can even specify several positive examples to get things that are related in the provided context and provide negative examples to say what should not be considered as related. In the example below we are asking for all items that *relate to bed* only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('duvet', 0.7153074145317078),\n",
       " ('mattress', 0.6970944404602051),\n",
       " ('quilt', 0.6911396980285645),\n",
       " ('blanket', 0.684184193611145),\n",
       " ('matress', 0.6777754426002502),\n",
       " ('pillowcase', 0.6747006177902222),\n",
       " ('pillows', 0.6384958028793335),\n",
       " ('foam', 0.6347048878669739),\n",
       " ('sheets', 0.6338217854499817),\n",
       " ('satin', 0.6009149551391602)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get everything related to stuff on the bed\n",
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between two words in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even use the Word2Vec model to return the similarity between two words that are present in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7694259"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two identical words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28037652"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two unrelated words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the above three snippets computes the cosine similarity between the two specified words using word vectors of each. From the scores, it makes sense that `dirty` is highly similar to `smelly` but `dirty` is dissimilar to `clean`. If you do a similarity between two identical words, the score will be 1.0 as the range of the cosine similarity score will always be between [0.0-1.0]. You can read more about cosine similarity scoring [here](https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the odd one out\n",
    "You can even use Word2Vec to find odd items given a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding some of the parameters\n",
    "To train the model earlier, we had to set some parameters. Now, let's try to understand what some of them mean. For reference, this is the command that we used to train the model.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `size`\n",
    "The size of the dense vector to represent each token or word. If you have very limited data, then size should be a much smaller value. If you have lots of data, its good to experiment with various sizes. A value of 100-150 has worked well for me. \n",
    "\n",
    "### `window`\n",
    "The maximum distance between the target word and its neighboring word. If your neighbor's position is greater than the maximum window width to the left and the right, then, some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as its a decent sized window. \n",
    "\n",
    "### `min_count`\n",
    "Minimium frequency count of words. The model would ignore words that do not statisfy the `min_count`. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.\n",
    "\n",
    "### `workers`\n",
    "How many threads to use behind the scenes?\n",
    "\n",
    "### `sg`\n",
    "Set sg to 1 to use the skip gram model and set it to 0 to use CBOW. By default, sg is set to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When should you use Word2Vec?\n",
    "\n",
    "There are many application scenarios for Word2Vec. Imagine if you need to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you achieve that. You have a lexicon for not just sentiment, but for most words in the vocabulary. \n",
    "\n",
    "Beyond, raw unstructured text data, you could also use Word2Vec for more structured data. For example, if you had tags for a million stackoverflow questions and answers, you could find tags that are related to a given tag and recommend the related ones for exploration. You can do this by treating each set of co-occuring tags as a \"sentence\" and train a Word2Vec model on this data. Granted, you still need a large number of examples to make it work. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

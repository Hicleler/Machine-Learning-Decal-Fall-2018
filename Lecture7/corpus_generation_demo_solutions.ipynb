{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 1115390\n",
      "\n",
      "\n",
      "\n",
      "First 100 characters:\n",
      "\n",
      "['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', '\\n', '\\n', 'A', 'l', 'l', ':', '\\n', 'S', 'p', 'e', 'a', 'k', ',', ' ', 's', 'p', 'e', 'a', 'k', '.', '\\n', '\\n', 'F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n', 'Y', 'o', 'u']\n"
     ]
    }
   ],
   "source": [
    "CHARS = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\" \\\n",
    "        + \"!\\\"#$%&\\'()*+,-./:;â€”<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c\"\n",
    "\n",
    "corpus = []\n",
    "with open('shakespeare.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        for char in line.strip():\n",
    "            corpus.append(char)\n",
    "        corpus.append('\\n')\n",
    "\n",
    "print(\"Total number of characters:\", len(corpus))\n",
    "print(\"\\n\\n\")\n",
    "print(\"First 100 characters:\\n\")\n",
    "print(corpus[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of distinct chars: 101\n"
     ]
    }
   ],
   "source": [
    "char2idx = {char : i for i, char in enumerate(CHARS)}\n",
    "idx2char = {i : char for i, char in enumerate(CHARS)}\n",
    "\n",
    "NUM_CHARS = len(char2idx)\n",
    "print(\"Total number of distinct chars:\", NUM_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus with indices:\n",
      "[41, 18, 27, 28, 29, 95, 38, 18, 29, 18, 35, 14, 23, 77, 97, 37, 14, 15, 24, 27, 14, 95, 32, 14, 95, 25, 27, 24, 12, 14, 14, 13, 95, 10, 23, 34, 95, 15, 30, 27, 29, 17, 14, 27, 73, 95, 17, 14, 10, 27, 95, 22, 14, 95, 28, 25, 14, 10, 20, 75, 97, 97, 36, 21, 21, 77, 97, 54, 25, 14, 10, 20, 73, 95, 28, 25, 14, 10, 20, 75, 97, 97, 41, 18, 27, 28, 29, 95, 38, 18, 29, 18, 35, 14, 23, 77, 97, 60, 24, 30]\n",
      "\n",
      "Size of dataset: 2000\n"
     ]
    }
   ],
   "source": [
    "corpus_with_indices = [char2idx[char] for char in corpus]\n",
    "\n",
    "print(\"Corpus with indices:\")\n",
    "print(corpus_with_indices[:100])\n",
    "\n",
    "SIZE_OF_SNIPPET = 250\n",
    "dataset = []\n",
    "for _ in range(2000):\n",
    "    \n",
    "    snipped_start = np.random.randint(0, len(corpus_with_indices) - SIZE_OF_SNIPPET)\n",
    "    snipped = corpus_with_indices[snipped_start:snipped_start + SIZE_OF_SNIPPET]\n",
    "    \n",
    "    dataset.append((\n",
    "        torch.LongTensor(snipped[:-1]),\n",
    "        torch.LongTensor(snipped[1:])\n",
    "    ))\n",
    "\n",
    "print(\"\\nSize of dataset:\", len(dataset))\n",
    "\n",
    "X = torch.stack([xy[0] for xy in dataset])\n",
    "Y = torch.stack([xy[1] for xy in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ShakespeareGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=NUM_CHARS,\n",
    "            embedding_dim=self.embedding_size\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_size,\n",
    "            hidden_size=self.hidden_size\n",
    "        )\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=self.hidden_size,\n",
    "            out_features=NUM_CHARS\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, batched_inputs):\n",
    "\n",
    "        batch_size = batched_inputs.shape[1]\n",
    "        h, c = self.get_initial_hc(batch_size)\n",
    "        seq_len = batched_inputs.shape[0]\n",
    "\n",
    "        embeddings = self.embedding(batched_inputs)\n",
    "        outputs, (h, c) = self.lstm(\n",
    "                embeddings.reshape(seq_len, batch_size, self.embedding_size),\n",
    "                (h, c)\n",
    "        )\n",
    "        outputs = self.linear(torch.squeeze(outputs))\n",
    "\n",
    "        return outputs, (h, c)\n",
    "\n",
    "\n",
    "    def get_initial_hc(self, batch_size):\n",
    "\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
    "                torch.zeros(1, batch_size, self.hidden_size))\n",
    "\n",
    "\n",
    "    def generate(self, initial_token=' ', num_tokens=100, temperature=1):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "        \n",
    "            token = torch.LongTensor([char2idx[initial_token]])\n",
    "            h, c = self.get_initial_hc(1)\n",
    "            chars = []\n",
    "            \n",
    "            for _ in range(num_tokens):\n",
    "                \n",
    "                chars.append(idx2char[token.item()])\n",
    "                \n",
    "                inp = self.embedding(token)\n",
    "                out, (h, c) = self.lstm(inp.reshape(1, 1, self.embedding_size), (h, c))\n",
    "                dist = self.linear(out.reshape(1, -1))\n",
    "                dist = dist.data.view(-1).div(temperature).exp()\n",
    "                chosen_i = torch.multinomial(dist, 1)[0]\n",
    "                token = torch.LongTensor([chosen_i])\n",
    "                \n",
    "            return ''.join(chars[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "LR = 0.1\n",
    "BETA = 0.8\n",
    "EMBEDDING_SIZE = 100\n",
    "HIDDEN_SIZE = 64\n",
    "\n",
    "USE_PRETRAINED = True\n",
    "\n",
    "net = ShakespeareGenerator(EMBEDDING_SIZE, HIDDEN_SIZE).float()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=BETA)\n",
    "\n",
    "if USE_PRETRAINED:\n",
    "    net.load_state_dict(torch.load('shakespeare.pt', map_location=lambda storage, loc: storage))\n",
    "    \n",
    "else:\n",
    "    for _ in range(EPOCHS):\n",
    "\n",
    "        output, _ = net(X.transpose(0, 1))\n",
    "        output = output.transpose(0, 1)\n",
    "\n",
    "        loss = criterion(output.reshape(-1, NUM_CHARS), Y.reshape(-1))\n",
    "\n",
    "        print(loss.item())\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trand the dight, of can and to't not Stere.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Am ill shall of pryrider:\n",
      "Come he shall ams most whence he suffy most,\n",
      "Apbante,\n",
      "Which father, thou two with onge a speading to breagued hersels tougibeariet you had his thredly your good me; and ontage\n",
      "Thou en me rade?\n",
      "\n",
      "KING HENRY VI:\n",
      "Brore sized, guer.\n",
      "\n",
      "AUFERON:\n",
      "And and it a sustion burston give visinent:\n",
      "KING\n",
      "Spest no more might powion, that aquers sometance?\n",
      "Nawres.\n",
      "As the distrucicitse: goilt a feards, mispoice, sold of mustage is corare Claudw'cared\n",
      "How deiple.\n",
      "\n",
      "PETRUCHIO:\n",
      "What of above are the wothing: thing steen,\n",
      "And Riunts you.\n",
      "\n",
      "Sthear a suckem; end desuctaitle\n",
      "Besest jeart man some the pray thelace,\n",
      "whither no true?\n",
      "Have entaither by histing thing in gendlonequ: mill nep if do to can desomelake conqonnow though your feence calient, he no do see again and huddongy now I that you conjest folke\n",
      "faress, pown. I dust this night, Eranse of to more reven aleled.\n",
      "\n",
      "CLAUDIO:\n",
      "Thighth all, you untime be wheed\n",
      "With him aled can\n"
     ]
    }
   ],
   "source": [
    "print(net.generate(temperature=1, num_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinyow, to Fixtgate-berder? Citer lit: you I,\n",
      "whattincior,\n",
      "If peo whou,\n",
      "Do\n",
      "\n",
      "EDWARD:\n",
      "Grth\n",
      "acly him;\n",
      "The am-end scieve\n",
      "My\n",
      "ar orn\n",
      "And him it meought, no;\n",
      "Heep give yet my Defid, bid!\n",
      "\n",
      "LART:\n",
      "O irer.\n",
      "Lorjont, never.\n",
      "\n",
      "ATlurs,\n",
      "Some, my remajedancars\n",
      "Yethiniable;\n",
      "Craturn'd?\n",
      "\n",
      "CAMELLERSE:\n",
      "I be ratdech'ces you a from that;\n",
      "Of vientomedfore give, cals.\n",
      "\n",
      "Thim;\n",
      "Tno lappal-what if like you, heixte'll shrivin; that this are dist!\n",
      "Mares Kience arrably.\n",
      "\n",
      "JULIETER:\n",
      "Meen,\n",
      "Plaught break, Stquecy-paw'd natue he mire, his clantothan? gell fulm tiscie; more now and Nocry this lordsain pady jourtageferther\n",
      "blobbe\n",
      "Thenir,--\n",
      "OLvar'd what of my vasase 'twurim! Ay.\n",
      "\n",
      "CAMILLO:\n",
      "Razpanning by?\n",
      "They pargait wea,\n",
      "Go; nigh! solet'cain. Leisely unted?\n",
      " meys?\n",
      "Come Tydol.\n",
      "\n",
      "YORY ANE VISAN:\n",
      "'Blo scoing,\n",
      "YORK:\n",
      "For' gitifors, this theix thir's exace.\n",
      "Sham sigong over tigant:\n",
      "Let taxtiwould\n",
      "'Tibl EpSHN PORD:\n",
      "hat's gix yange,' forn aking?\n",
      "Nuceld:\n",
      "Hould, toward,\n",
      "Have motewared.\n",
      "Co lold?\n",
      "Naye good ceptal dust;\n",
      "Renttedw's viorake, \n"
     ]
    }
   ],
   "source": [
    "print(net.generate(temperature=1.5, num_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sea the seem the father shall his with the some shall the shall make the prick the see the death the death and the sea the son of the love the man and the so man to the should shall me the sea the father the live the son the father be the see the so be my countresseld the sent the lord, the sight a shall the sea the be a see the hour the say the shall the shall to the shall you have here the see the sea the see the so man the soon the sometant the strent the man the so for my counted the some the lords the so man the be me the for the shall the so man the see the so father the live the so man the death the stain my lord, the shall the sea the live the countere the pery come the should stand the death shall be the death the so shall the see shall be my so fair me the son the so should the sea the dear the sea the seemence the shall the death as the shall the seem the not the see the sease the grace the heart he have the so disting the so man the heart the seeman the come the sea th\n"
     ]
    }
   ],
   "source": [
    "print(net.generate(temperature=0.25, num_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
